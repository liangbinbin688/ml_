{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用K-Means算法对未标记数据分组\n",
    "![title](images/001.png)\n",
    "簇识别：\n",
    "\n",
    "簇识别给出了聚类结果的含义，假定有一些数据，簇识别会告诉我们这些簇到底都是些什么。\n",
    "\n",
    "聚类与分类的区别：\n",
    "\n",
    "分类的目标事先已知，但是聚类的类别没有事先定义，故聚类也称无监督分类。\n",
    "\n",
    "### k均值聚类算法\n",
    "![title](images/002.png)\n",
    "\n",
    "K-均值是发现给定数据集的k个簇的算法，簇个数k是用户给定的，每一个簇通过其质心（centroid），即簇中所有点的中心来描述。\n",
    "\n",
    "K-均值算法工作流程：\n",
    "\n",
    "+ 1.随机确定k个初始点作为质心 \n",
    "\n",
    "+ 2.将数据集中的每个点分配到一个簇中，即为每个点找到距离其最近的质心，并将其分配给该质心所对应的簇，该步骤完成后，每个簇的质心更新为该簇所有点的平均值。\n",
    "\n",
    "伪代码：\n",
    "\n",
    "随机创建K个质心为起始点  \n",
    "当任意一个点的簇分配结果发生变化时  \n",
    "    对每一个数据点  \n",
    "         对每个质心  \n",
    "              计算数据点和之心之间的距离  \n",
    "         将数据点分配到距离最近的簇中  \n",
    "    对每个簇，计算所有点的均值更新质心\n",
    "    \n",
    "具体做法：\n",
    "\n",
    "+ 1.随机选取K个聚类质心点（cluster centroids）为${\\mu}_1$,${\\mu}_2$,${\\mu}_3$,...,${\\mu}_k$\n",
    "\n",
    "+ 2.重复每个样例，计算其应该属于的类$$c^(i):=argmin_i{||x^{(i)}-{\\mu}_j||^2}$$\n",
    "对于每一个类j，重新计算该类的质心\n",
    "![title](images/003.png)\n",
    "K是我们事先给定的聚类数，${c^{i}}$代表样例i与k个类中距离最近的那个类，${c^{i}}$的值是1到k中的一个。质心${\\mu}_j$代表我们对属于同一个类的样本中心点的猜测，拿星团模型来解释就是要将所有的星星聚成k个星团，首先随机选取k个宇宙中的点（或者k个星星）作为k个星团的质心.\n",
    "\n",
    "[1]对于每一个星星计算其到k个质心中每一个的距离，然后选取距离最近的那个星团作为${c^{i}}$，这样经过第一步每一个星星都有了所属的星团；\n",
    "[2]对于每一个星团，重新计算它的质心${\\mu}_j$（对里面所有的星星坐标求平均）。重复迭代第一步和第二步直到质心不变或者变化很小。\n",
    "\n",
    "一般流程：\n",
    "![title](images/004.png)\n",
    "\n",
    "收敛性：\n",
    "![title](images/005.png)\n",
    "\n",
    "首先定义畸变函数：\n",
    "    \n",
    "   J函数表示每个样本点到其质心的距离平方和。K-means是要将J调整到最小。假设当前J没有达到最小值，那么首先可以固定每个类的质心${\\mu}_j$,调整每个样例的所属类别$c^{(i)}$来让J函数减少，同样。固定$c^{(i)}$,调整每个类的质心${\\mu}_j$也可以使J减少。这两个过程就是内循环中使J单调递减的过程。当J递减到最小时，${\\mu}$和$c$也同时收敛。（在理论上，可以有多组不同的clip_image018[7]和c值能够使得J取得最小值，但这种现象实际上很少见）。\n",
    "   \n",
    "  由于畸变函数J是非凸函数，意味着我们不能保证取得的最小值是全局最小值，也就是说k-means对质心初始位置的选取比较敏感，但一般情况下k-means达到的局部最优已经满足需求。但如果你怕陷入局部最优，那么可以选取不同的初始值跑多遍k-means，然后取其中最小的J对应的${\\mu}$和$c$也输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 计算样本点之间的距离\n",
    "def euclDistance(vector1, vector2):\n",
    "    return sqrt(sum(power(vector2 - vector1, 2)))\n",
    "\n",
    "\n",
    "# 随机初始化k个中心点\n",
    "def initCentroids(dataSet, k):\n",
    "    numSamples, dim = dataSet.shape\n",
    "    centroids = zeros((k, dim))\n",
    "    for i in range(k):\n",
    "        # uniform表示从0，样本个数之间取随机的index\n",
    "        index = int(random.uniform(0, numSamples))\n",
    "        centroids[i, :] = dataSet[index, :]\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# k-means cluster\n",
    "def kmeans(dataSet, k):\n",
    "    numSamples = dataSet.shape[0]\n",
    "    # first column stores which cluster this sample belongs to,\n",
    "    # second column stores the error between this sample and its centroid\n",
    "    clusterAssment = mat(zeros((numSamples, 2)))\n",
    "    clusterChanged = True\n",
    "\n",
    "    ## step 1: init centroids\n",
    "    centroids = initCentroids(dataSet, k)\n",
    "\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        ## for each sample\n",
    "        for i in range(numSamples):\n",
    "            minDist = 100000.0\n",
    "            minIndex = 0\n",
    "            ## for each centroid\n",
    "            ## step 2: find the centroid who is closest\n",
    "            for j in range(k):\n",
    "                distance = euclDistance(centroids[j, :], dataSet[i, :])\n",
    "                if distance < minDist:\n",
    "                    minDist = distance\n",
    "                    minIndex = j\n",
    "\n",
    "            ## step 3: update its cluster\n",
    "            if clusterAssment[i, 0] != minIndex:\n",
    "                clusterChanged = True\n",
    "                clusterAssment[i, :] = minIndex, minDist ** 2\n",
    "\n",
    "        ## step 4: update centroids\n",
    "        for j in range(k):\n",
    "            pointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]]\n",
    "            centroids[j, :] = mean(pointsInCluster, axis=0)\n",
    "\n",
    "    print('Congratulations, cluster complete!')\n",
    "    return centroids, clusterAssment\n",
    "\n",
    "\n",
    "# show your cluster only available with 2-D data\n",
    "def showCluster(dataSet, k, centroids, clusterAssment):\n",
    "    numSamples, dim = dataSet.shape\n",
    "    if dim != 2:\n",
    "        print(\"Sorry! I can not draw because the dimension of your data is not 2!\")\n",
    "        return 1\n",
    "\n",
    "    mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "    if k > len(mark):\n",
    "        print(\"Sorry! Your k is too large! please contact Zouxy\")\n",
    "        return 1\n",
    "\n",
    "    # draw all samples\n",
    "    for i in range(numSamples):\n",
    "        markIndex = int(clusterAssment[i, 0])\n",
    "        plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex])\n",
    "\n",
    "    mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '<b', 'pb']\n",
    "    # draw the centroids\n",
    "    for i in range(k):\n",
    "        plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize=12)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    ## step 1: load data\n",
    "    print(\"step 1: load data...\")\n",
    "    dataSet = []\n",
    "    fileIn = open('testSet.txt')\n",
    "    for line in fileIn.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataSet.append([float(lineArr[0]), float(lineArr[1])])\n",
    "\n",
    "    ## step 2: clustering...\n",
    "    print( \"step 2: clustering...\")\n",
    "    dataSet = mat(dataSet)\n",
    "    k = 4\n",
    "    centroids, clusterAssment = kmeans(dataSet, k)\n",
    "\n",
    "    ## step 3: show the result\n",
    "    print(\"step 3: show the result...\")\n",
    "    showCluster(dataSet, k, centroids, clusterAssment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  二分K-均值算法\n",
    "\n",
    "    该算法首先将所有的点当成一个簇，然后将该簇一分为二。之后选择其中一个簇进行划分，选择哪一个簇进行划分取决于对其划分是否可以最大程度降低SSE的值。不断重复该过程，直到达到用户所需要的簇个数为止。\n",
    "    \n",
    "    \n",
    "将所有的点看成一个簇\n",
    "当簇数目小于k时\n",
    "   对每一个簇\n",
    "        计算总误差\n",
    "        在给定的簇上面进行二分k-均值聚类\n",
    "        计算一分为二之后的总误差\n",
    "    选择使得误差最小的那个簇进行划分\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# calculate Euclidean distance\n",
    "def euclDistance(vector1, vector2):\n",
    "    return sqrt(sum(power(vector2 - vector1, 2)))\n",
    "\n",
    "\n",
    "# init centroids with random samples\n",
    "def initCentroids(dataSet, k):\n",
    "    numSamples, dim = dataSet.shape\n",
    "    centroids = zeros((k, dim))\n",
    "    for i in range(k):\n",
    "        index = int(random.uniform(0, numSamples))\n",
    "        centroids[i, :] = dataSet[index, :]\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# k-means cluster\n",
    "def kmeans(dataSet, k):\n",
    "    numSamples = dataSet.shape[0]\n",
    "    # first column stores which cluster this sample belongs to,\n",
    "    # second column stores the error between this sample and its centroid\n",
    "    clusterAssment = mat(zeros((numSamples, 2)))\n",
    "    clusterChanged = True\n",
    "\n",
    "    ## step 1: init centroids\n",
    "    centroids = initCentroids(dataSet, k)\n",
    "\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        ## for each sample\n",
    "        for i in range(numSamples):\n",
    "            minDist = 100000.0\n",
    "            minIndex = 0\n",
    "            ## for each centroid\n",
    "            ## step 2: find the centroid who is closest\n",
    "            for j in range(k):\n",
    "                distance = euclDistance(centroids[j, :], dataSet[i, :])\n",
    "                if distance < minDist:\n",
    "                    minDist = distance\n",
    "                    minIndex = j\n",
    "\n",
    "            ## step 3: update its cluster\n",
    "            if clusterAssment[i, 0] != minIndex:\n",
    "                clusterChanged = True\n",
    "                clusterAssment[i, :] = minIndex, minDist ** 2\n",
    "\n",
    "        ## step 4: update centroids\n",
    "        for j in range(k):\n",
    "            pointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]]\n",
    "            centroids[j, :] = mean(pointsInCluster, axis=0)\n",
    "\n",
    "\n",
    "    return centroids, clusterAssment\n",
    "\n",
    "\n",
    "# bisecting k-means cluster\n",
    "def biKmeans(dataSet, k):\n",
    "    numSamples = dataSet.shape[0]\n",
    "    # first column stores which cluster this sample belongs to,\n",
    "    # second column stores the error between this sample and its centroid\n",
    "    clusterAssment = mat(zeros((numSamples, 2)))\n",
    "\n",
    "    # step 1: the init cluster is the whole data set\n",
    "    centroid = mean(dataSet, axis=0).tolist()[0]\n",
    "    centList = [centroid]\n",
    "    for i in range(numSamples):\n",
    "        clusterAssment[i, 1] = euclDistance(mat(centroid), dataSet[i, :]) ** 2\n",
    "\n",
    "    while len(centList) < k:\n",
    "        # min sum of square error\n",
    "        minSSE = 100000.0\n",
    "        numCurrCluster = len(centList)\n",
    "        # for each cluster\n",
    "        for i in range(numCurrCluster):\n",
    "            # step 2: get samples in cluster i\n",
    "            pointsInCurrCluster = dataSet[nonzero(clusterAssment[:, 0].A == i)[0], :]\n",
    "\n",
    "            # step 3: cluster it to 2 sub-clusters using k-means\n",
    "            centroids, splitClusterAssment = kmeans(pointsInCurrCluster, 2)\n",
    "\n",
    "            # step 4: calculate the sum of square error after split this cluster\n",
    "            splitSSE = sum(splitClusterAssment[:, 1])\n",
    "            notSplitSSE = sum(clusterAssment[nonzero(clusterAssment[:, 0].A != i)[0], 1])\n",
    "            currSplitSSE = splitSSE + notSplitSSE\n",
    "\n",
    "            # step 5: find the best split cluster which has the min sum of square error\n",
    "            if currSplitSSE < minSSE:\n",
    "                minSSE = currSplitSSE\n",
    "                bestCentroidToSplit = i\n",
    "                bestNewCentroids = centroids.copy()\n",
    "                bestClusterAssment = splitClusterAssment.copy()\n",
    "\n",
    "        # step 6: modify the cluster index for adding new cluster\n",
    "        bestClusterAssment[nonzero(bestClusterAssment[:, 0].A == 1)[0], 0] = numCurrCluster\n",
    "        bestClusterAssment[nonzero(bestClusterAssment[:, 0].A == 0)[0], 0] = bestCentroidToSplit\n",
    "\n",
    "        # step 7: update and append the centroids of the new 2 sub-cluster\n",
    "        centList[bestCentroidToSplit] = bestNewCentroids[0, :]\n",
    "        centList.append(bestNewCentroids[1, :])\n",
    "\n",
    "        # step 8: update the index and error of the samples whose cluster have been changed\n",
    "        clusterAssment[nonzero(clusterAssment[:, 0].A == bestCentroidToSplit), :] = bestClusterAssment\n",
    "\n",
    "\n",
    "    return mat(centList), clusterAssment\n",
    "\n",
    "\n",
    "# show your cluster only available with 2-D data\n",
    "def showCluster(dataSet, k, centroids, clusterAssment):\n",
    "    numSamples, dim = dataSet.shape\n",
    "    if dim != 2:\n",
    "        print(\"Sorry! I can not draw because the dimension of your data is not 2!\")\n",
    "        return 1\n",
    "\n",
    "    mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "    if k > len(mark):\n",
    "        print(\"Sorry! Your k is too large!\")\n",
    "        return 1\n",
    "\n",
    "    # draw all samples\n",
    "    for i in range(numSamples):\n",
    "        markIndex = int(clusterAssment[i, 0])\n",
    "        plt.plot(dataSet[i, 0], dataSet[i, 1], mark[markIndex])\n",
    "\n",
    "    mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '<b', 'pb']\n",
    "    # draw the centroids\n",
    "    for i in range(k):\n",
    "        plt.plot(centroids[i, 0], centroids[i, 1], mark[i], markersize=12)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #################################################\n",
    "    # kmeans: k-means cluster\n",
    "    # Author : zouxy\n",
    "    # Date   : 2013-12-25\n",
    "    # HomePage : http://blog.csdn.net/zouxy09\n",
    "    # Email  : zouxy09@qq.com\n",
    "    #################################################\n",
    "\n",
    "    from numpy import *\n",
    "    import time\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ## step 1: load data\n",
    "    print(\"step 1: load data...\")\n",
    "    dataSet = []\n",
    "    fileIn = open('testSet2.txt')\n",
    "    for line in fileIn.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataSet.append([float(lineArr[0]), float(lineArr[1])])\n",
    "\n",
    "    ## step 2: clustering...\n",
    "    print( \"step 2: clustering...\")\n",
    "    dataSet = mat(dataSet)\n",
    "    k = 3\n",
    "    centroids, clusterAssment = biKmeans(dataSet, k)\n",
    "\n",
    "    ## step 3: show the result\n",
    "    print(\"step 3: show the result...\")\n",
    "    showCluster(dataSet, k, centroids, clusterAssment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
